{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as sms\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. In this problem, you will use the Carseats data set attached in the assignment (Carseats.csv) for linear regression.\n",
    "### (a) [5 pts] Fit a multiple linear regression model to predict Sales using Price, Urban, and US. Report the R2 of the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.239\n",
      "Model:                            OLS   Adj. R-squared:                  0.234\n",
      "Method:                 Least Squares   F-statistic:                     41.52\n",
      "Date:                Sun, 03 Apr 2022   Prob (F-statistic):           2.39e-23\n",
      "Time:                        15:34:03   Log-Likelihood:                -927.66\n",
      "No. Observations:                 400   AIC:                             1863.\n",
      "Df Residuals:                     396   BIC:                             1879.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     13.0435      0.651     20.036      0.000      11.764      14.323\n",
      "Price         -0.0545      0.005    -10.389      0.000      -0.065      -0.044\n",
      "Urban         -0.0219      0.272     -0.081      0.936      -0.556       0.512\n",
      "US             1.2006      0.259      4.635      0.000       0.691       1.710\n",
      "==============================================================================\n",
      "Omnibus:                        0.676   Durbin-Watson:                   1.912\n",
      "Prob(Omnibus):                  0.713   Jarque-Bera (JB):                0.758\n",
      "Skew:                           0.093   Prob(JB):                        0.684\n",
      "Kurtosis:                       2.897   Cond. No.                         628.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Import CSV file\n",
    "carseats_data = pd.read_csv('Carseats.csv')\n",
    "# Replace 'Yes' and 'No' cells into 1 and 0 each.\n",
    "carseats_data['US'] = carseats_data['US'].replace(['Yes'],1)\n",
    "carseats_data['US'] = carseats_data['US'].replace(['No'],0)\n",
    "carseats_data['Urban'] = carseats_data['Urban'].replace(['Yes'],1)\n",
    "carseats_data['Urban'] = carseats_data['Urban'].replace(['No'],0)\n",
    "result = sm.ols('Sales ~ Price + Urban + US',data = carseats_data).fit()\n",
    "print(result.summary())\n",
    "# X = np.column_stack((carseats_data['Price'], carseats_data['Urban'], carseats_data['US']))\n",
    "# Y =carseats_data['Sales']\n",
    "# X2 = sm.add_constant(X)\n",
    "# prob1_result = sm.OLS(Y, X2)\n",
    "# prob1_result = prob1_result.fit()\n",
    "# print(prob1_result.summary())\n",
    "\n",
    "\n",
    "# # Only interested in several columns\n",
    "# A=carseats_data[['Sales', 'Price', 'Urban', 'US']]\n",
    "# lin_variables = np.array(A.values,'int')\n",
    "# # Split into predictors and result variables.\n",
    "# Y_lin_variables=lin_variables[:,0]\n",
    "# X_ones=np.ones((Y_lin_variables.size,1),dtype=int)\n",
    "# X_lin_variables=np.column_stack([X_ones,pd.DataFrame(lin_variables[:,1:4])])\n",
    "# # The Least Square Estimator\n",
    "# X_coefficient= np.matmul(np.linalg.inv(np.matmul(np.transpose(X_lin_variables),X_lin_variables)), np.transpose(X_lin_variables))\n",
    "# beta=np.matmul(X_coefficient,Y_lin_variables)\n",
    "# print(\"------------------------------------------------------\")\n",
    "# print(\"a multiple linear regression model to predict Sales using Price, Urban, and US is \")\n",
    "# print(\"(\",beta[0],\") + (\",beta[1],\")*\",\"Price\",\" + (\",beta[2],\") * Urban + (\",beta[3],\") * US\")\n",
    "# print(\"------------------------------------------------------\")\n",
    "# # Finding R-squared\n",
    "# Y_lin_predict=np.dot(X_lin_variables, beta)\n",
    "# rss=np.sum(np.square(Y_lin_variables-Y_lin_predict))\n",
    "# tss=np.sum(np.square((Y_lin_variables-np.mean(Y_lin_variables))))\n",
    "# r_squared=1-(rss/tss)\n",
    "# print(\"R-squared of the model is\")\n",
    "# print(r_squared)\n",
    "# print(\"------------------------------------------------------\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (b) [10 pts] Provide an interpretation of each coefficient in the model. Be careful — some of the variables in the model are qualitative"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- The intercept, 13.0435, refers to the sales on baseline, where price is 0 and the value to 'urban' and 'US' is 'NO'\n",
    "- A unit change in price is associated with a -0.0544 change in Sales, while all variables stay fixed. It is supported by the fact that p-value is extremely small.\n",
    "- Living in urban area will have as negative effect as -0.0219 on sales. However, large p-value suggests no statistical evidence of a real difference on sales by urban variable.\n",
    "- Living in US will have as positive effect as 1.2006 on sales. It is statistically supported by small p-value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (c) [5 pts] Write out the model in equation form, being careful to handle the qualitative variables properly."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "beta=[13.0435,-0.0545,-0.0219,1.2006]\n",
    "print(\"a multiple linear regression model to predict Sales using Price, Urban, and US is \")\n",
    "print(\"(\",beta[0],\") + (\",beta[1],\")*\",\"Price\",\" + (\",beta[2],\") * Urban + (\",beta[3],\") * US\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a multiple linear regression model to predict Sales using Price, Urban, and US is \n",
      "( 13.0435 ) + ( -0.0545 )* Price  + ( -0.0219 ) * Urban + ( 1.2006 ) * US\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (d) [5 pts] For which predictor variable j can you reject the null hypothesis H0 : βj =0?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only Price and US can reject the null hypothesis based on p-values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (e) [5 pts] On the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is evidence of association with the outcome."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "result = sm.ols('Sales ~ Price  + US',data = carseats_data).fit()\n",
    "print(result.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.239\n",
      "Model:                            OLS   Adj. R-squared:                  0.235\n",
      "Method:                 Least Squares   F-statistic:                     62.43\n",
      "Date:                Sun, 03 Apr 2022   Prob (F-statistic):           2.66e-24\n",
      "Time:                        15:34:31   Log-Likelihood:                -927.66\n",
      "No. Observations:                 400   AIC:                             1861.\n",
      "Df Residuals:                     397   BIC:                             1873.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     13.0308      0.631     20.652      0.000      11.790      14.271\n",
      "Price         -0.0545      0.005    -10.416      0.000      -0.065      -0.044\n",
      "US             1.1996      0.258      4.641      0.000       0.692       1.708\n",
      "==============================================================================\n",
      "Omnibus:                        0.666   Durbin-Watson:                   1.912\n",
      "Prob(Omnibus):                  0.717   Jarque-Bera (JB):                0.749\n",
      "Skew:                           0.092   Prob(JB):                        0.688\n",
      "Kurtosis:                       2.895   Cond. No.                         607.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (f) [10 pts] How well do the models in Part (a) and Part (e) fit the data? Compare the two models. Can you say one model is better than the other based on R2? Provide justification for your answer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Both models have the same R-squared value, which means we cannot compare both based on R-squared.\n",
    "However, a larger f-value may note that the model in part (e) fit the data much better than that in part (a)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (g) [10 pts] Using the model from (e), obtain 95% confidence intervals for the coefficient(s)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "                  0          1\nIntercept  11.79032  14.271265\nPrice      -0.06476  -0.044195\nUS          0.69152   1.707766",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Intercept</th>\n      <td>11.79032</td>\n      <td>14.271265</td>\n    </tr>\n    <tr>\n      <th>Price</th>\n      <td>-0.06476</td>\n      <td>-0.044195</td>\n    </tr>\n    <tr>\n      <th>US</th>\n      <td>0.69152</td>\n      <td>1.707766</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.conf_int(alpha=0.05, cols=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. [50 pts] In class, we used the example of the logistic regression model to predict the probability of default using income and balance on the Default data set attached in the assignment (Default.csv). In this problem, we will estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.\n",
    "### (a) [10 pts] Fit a logistic regression model that uses income and balance to predict default using the validation set approach, and estimate the test error of this model. In order to do this, you must perform the following steps:\n",
    "- i Split the sample set into a training set and a validation set.\n",
    "- ii Fit a multiple logistic regression model using only the training observations.\n",
    "- iii Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5.\n",
    "- iv Compute the validation set error, which is the fraction of the observations in\n",
    "the validation set that are misclassified."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-11.86423424]\n",
      "[[2.07470644e-05 5.85629664e-03]]\n",
      "      0    1     2\n",
      "0  4809  116  4925\n",
      "1    26   49    75\n",
      "2  4835  165  5000\n",
      "False Positive Rate is 0.0054\n",
      "False Negative Rate is 0.703\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# split into a training set and validation set\n",
    "default_data = pd.read_csv('Default.csv')\n",
    "default_data['default'] = default_data['default'].replace(['Yes'],1)\n",
    "default_data['default'] = default_data['default'].replace(['No'],0)\n",
    "default_data['student'] = default_data['student'].replace(['Yes'],1)\n",
    "default_data['student'] = default_data['student'].replace(['No'],0)\n",
    "train, test = train_test_split(default_data, test_size=0.5)\n",
    "\n",
    "X_train=train[[\"income\",\"balance\"]]\n",
    "Y_train=train[\"default\"]\n",
    "X_test=test[[\"income\",\"balance\"]]\n",
    "Y_test=test[\"default\"]\n",
    "\n",
    "# Fit a model using training data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "print(model.intercept_)\n",
    "print(model.coef_)\n",
    "\n",
    "#Predict each individual from test data\n",
    "P_test=pd.DataFrame(model.predict_proba(X_test), index=X_test.index)\n",
    "P_test = pd.DataFrame((model.predict_proba(X_test)[:,1] >= 0.5).astype(int), index=X_test.index)\n",
    "P_test.columns = [\"predicted default\"]\n",
    "P_test_predict=pd.merge(test, P_test, left_index=True, right_index=True)\n",
    "# Finding Test Error\n",
    "result_table= [[0,0,0],[0,0,0],[0,0,0]]\n",
    "for index, row in P_test_predict.iterrows():\n",
    "    if row[\"predicted default\"]==0:\n",
    "        if row[\"default\"] ==0 :\n",
    "            result_table[0][0]+=1\n",
    "            result_table[2][0]+=1\n",
    "        elif row[\"default\"] ==1:\n",
    "            result_table[0][1]+=1\n",
    "            result_table[2][1]+=1\n",
    "        result_table[0][2]+=1\n",
    "    elif row[\"predicted default\"]==1:\n",
    "        if row[\"default\"] ==0:\n",
    "            result_table[1][0]+=1\n",
    "            result_table[2][0]+=1\n",
    "        elif row[\"default\"] ==1:\n",
    "            result_table[1][1]+=1\n",
    "            result_table[2][1]+=1\n",
    "        result_table[1][2]+=1\n",
    "    result_table[2][2]+=1\n",
    "result_df= pd.DataFrame(result_table)\n",
    "result_df.columns=[0,1,2]\n",
    "print(result_df)\n",
    "print(\"False Positive Rate is\",round( result_table[1][0]/result_table[2][0],4))\n",
    "print(\"False Negative Rate is\",round( result_table[0][1]/result_table[2][1],4))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (b) [10 pts] Provide an interpretation of each coefficient in the trained model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.074226\n",
      "         Iterations 10\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                 5000\n",
      "Model:                          Logit   Df Residuals:                     4997\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sun, 03 Apr 2022   Pseudo R-squ.:                  0.4491\n",
      "Time:                        21:27:35   Log-Likelihood:                -371.13\n",
      "converged:                       True   LL-Null:                       -673.71\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.895e-132\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -11.5465      0.636    -18.145      0.000     -12.794     -10.299\n",
      "income      2.213e-05   7.28e-06      3.039      0.002    7.86e-06    3.64e-05\n",
      "balance        0.0055      0.000     16.930      0.000       0.005       0.006\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "X_train=sms.tools.tools.add_constant(X_train)\n",
    "model= sms.api.Logit(Y_train, X_train).fit()\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Log odds can be represented as log(p/(1-p))=(-11.54652535)+(2.213e-05)*income+(0.0055)*balance.\n",
    "That is, a unit increase in income is associated with an increase in the log odds of default by 2.213e-05 units.\n",
    "Also, a unit increase in balance is associated with an increase in the log odds of default by 0.0055 units.\n",
    "Above all are supported by a small p-value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (c) [15 pts] Perform 5-fold cross-validation using the same model as in Part (a). Write your own code for the K-fold cross-validation. How does the validation error of the cross-validation the differ from to the results in Part (a)?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #:  1\n",
      "      0    1     2\n",
      "0  7727  260  7987\n",
      "1    12    1    13\n",
      "2  7739  261  8000\n",
      "False Positive Rate is 0.0016\n",
      "False Negative Rate is 0.9962\n",
      "iteration #:  2\n",
      "      0    1     2\n",
      "0  7712  199  7911\n",
      "1    19   70    89\n",
      "2  7731  269  8000\n",
      "False Positive Rate is 0.0025\n",
      "False Negative Rate is 0.7398\n",
      "iteration #:  3\n",
      "      0    1     2\n",
      "0  7682  194  7876\n",
      "1    37   87   124\n",
      "2  7719  281  8000\n",
      "False Positive Rate is 0.0048\n",
      "False Negative Rate is 0.6904\n",
      "iteration #:  4\n",
      "      0    1     2\n",
      "0  7712  165  7877\n",
      "1    36   87   123\n",
      "2  7748  252  8000\n",
      "False Positive Rate is 0.0046\n",
      "False Negative Rate is 0.6548\n",
      "iteration #:  5\n",
      "      0    1     2\n",
      "0  7707  190  7897\n",
      "1    24   79   103\n",
      "2  7731  269  8000\n",
      "False Positive Rate is 0.0031\n",
      "False Negative Rate is 0.7063\n",
      "Overall misclassified data is  1136\n"
     ]
    }
   ],
   "source": [
    "default_data_randomized=default_data.sample(frac=1) # shuffle raw default data\n",
    "misclassified=0\n",
    "for count in range(5):\n",
    "    train = default_data_randomized.iloc[2000*count:2000*(count+1),:]\n",
    "    test= pd.concat([default_data_randomized.iloc[:2000*count,:],default_data_randomized.iloc[2000*(count+1):,:]])\n",
    "\n",
    "\n",
    "    X_train=train[[\"income\",\"balance\"]]\n",
    "    Y_train=train[\"default\"]\n",
    "    X_test=test[[\"income\",\"balance\"]]\n",
    "    Y_test=test[\"default\"]\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train,Y_train)\n",
    "    P_test=pd.DataFrame(model.predict_proba(X_test), index=X_test.index)\n",
    "    P_test = pd.DataFrame((model.predict_proba(X_test)[:,1] >= 0.5).astype(int), index=X_test.index)\n",
    "    P_test.columns = [\"predicted default\"]\n",
    "    P_test_predict=pd.merge(test, P_test, left_index=True, right_index=True)\n",
    "    print(\"iteration #: \", count+1)\n",
    "    result_table= [[0,0,0],[0,0,0],[0,0,0]]\n",
    "    for index, row in P_test_predict.iterrows():\n",
    "        if row[\"predicted default\"]==0:\n",
    "            if row[\"default\"] ==0 :\n",
    "                result_table[0][0]+=1\n",
    "                result_table[2][0]+=1\n",
    "            elif row[\"default\"] ==1:\n",
    "                result_table[0][1]+=1\n",
    "                result_table[2][1]+=1\n",
    "            result_table[0][2]+=1\n",
    "        elif row[\"predicted default\"]==1:\n",
    "            if row[\"default\"] ==0:\n",
    "                result_table[1][0]+=1\n",
    "                result_table[2][0]+=1\n",
    "            elif row[\"default\"] ==1:\n",
    "                result_table[1][1]+=1\n",
    "                result_table[2][1]+=1\n",
    "            result_table[1][2]+=1\n",
    "        result_table[2][2]+=1\n",
    "    result_df= pd.DataFrame(result_table)\n",
    "    result_df.columns=[0,1,2]\n",
    "    misclassified+=result_table[1][0]+result_table[0][1]\n",
    "    print(result_df)\n",
    "    print(\"False Positive Rate is\",round( result_table[1][0]/result_table[2][0],4))\n",
    "    print(\"False Negative Rate is\",round( result_table[0][1]/result_table[2][1],4))\n",
    "print(\"Overall # of misclassified data is \",misclassified)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The validation error is much better in Part (a) compared to part (c). This is because less data was made use of in part (c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (d) [15 pts] Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the 5-fold cross-validation set approach. Comment on whether or not including a dummy variable for student would lead to a reduction in the test error rate."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #:  1\n",
      "      0    1     2\n",
      "0  7689  207  7896\n",
      "1    50   54   104\n",
      "2  7739  261  8000\n",
      "False Positive Rate is 0.0065\n",
      "False Negative Rate is 0.7931\n",
      "iteration #:  2\n",
      "      0    1     2\n",
      "0  7695  223  7918\n",
      "1    39   43    82\n",
      "2  7734  266  8000\n",
      "False Positive Rate is 0.005\n",
      "False Negative Rate is 0.8383\n",
      "iteration #:  3\n",
      "      0    1     2\n",
      "0  7697  220  7917\n",
      "1    38   45    83\n",
      "2  7735  265  8000\n",
      "False Positive Rate is 0.0049\n",
      "False Negative Rate is 0.8302\n",
      "iteration #:  4\n",
      "      0    1     2\n",
      "0  7708  234  7942\n",
      "1    27   31    58\n",
      "2  7735  265  8000\n",
      "False Positive Rate is 0.0035\n",
      "False Negative Rate is 0.883\n",
      "iteration #:  5\n",
      "      0    1     2\n",
      "0  7697  198  7895\n",
      "1    28   77   105\n",
      "2  7725  275  8000\n",
      "False Positive Rate is 0.0036\n",
      "False Negative Rate is 0.72\n",
      "Overall misclassified data is  1264\n"
     ]
    }
   ],
   "source": [
    "# split into a training set and validation set\n",
    "default_data = pd.read_csv('Default.csv')\n",
    "default_data['default'] = default_data['default'].replace(['Yes'],1)\n",
    "default_data['default'] = default_data['default'].replace(['No'],0)\n",
    "default_data['student'] = default_data['student'].replace(['Yes'],1)\n",
    "default_data['student'] = default_data['student'].replace(['No'],0)\n",
    "default_data_randomized=default_data.sample(frac=1) # shuffle raw default data\n",
    "misclassified=0\n",
    "\n",
    "for count in range(5):\n",
    "    train = default_data_randomized.iloc[2000*count:2000*(count+1),:]\n",
    "    test= pd.concat([default_data_randomized.iloc[:2000*count,:],default_data_randomized.iloc[2000*(count+1):,:]])\n",
    "    X_train=train[[\"income\",\"balance\",\"student\"]]\n",
    "    Y_train=train[\"default\"]\n",
    "    X_test=test[[\"income\",\"balance\",\"student\"]]\n",
    "    Y_test=test[\"default\"]\n",
    "    # Fit a model using training data\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train,Y_train)\n",
    "    P_test=pd.DataFrame(model.predict_proba(X_test), index=X_test.index)\n",
    "    P_test = pd.DataFrame((model.predict_proba(X_test)[:,1] >= 0.5).astype(int), index=X_test.index)\n",
    "    P_test.columns = [\"predicted default\"]\n",
    "    P_test_predict=pd.merge(test, P_test, left_index=True, right_index=True)\n",
    "    print(\"iteration #: \", count+1)\n",
    "    result_table= [[0,0,0],[0,0,0],[0,0,0]]\n",
    "    for index, row in P_test_predict.iterrows():\n",
    "        if row[\"predicted default\"]==0:\n",
    "            if row[\"default\"] ==0 :\n",
    "                result_table[0][0]+=1\n",
    "                result_table[2][0]+=1\n",
    "            elif row[\"default\"] ==1:\n",
    "                result_table[0][1]+=1\n",
    "                result_table[2][1]+=1\n",
    "            result_table[0][2]+=1\n",
    "        elif row[\"predicted default\"]==1:\n",
    "            if row[\"default\"] ==0:\n",
    "                result_table[1][0]+=1\n",
    "                result_table[2][0]+=1\n",
    "            elif row[\"default\"] ==1:\n",
    "                result_table[1][1]+=1\n",
    "                result_table[2][1]+=1\n",
    "            result_table[1][2]+=1\n",
    "        result_table[2][2]+=1\n",
    "    result_df= pd.DataFrame(result_table)\n",
    "    result_df.columns=[0,1,2]\n",
    "    misclassified+=result_table[1][0]+result_table[0][1]\n",
    "    print(result_df)\n",
    "    print(\"False Positive Rate is\",round( result_table[1][0]/result_table[2][0],4))\n",
    "    print(\"False Negative Rate is\",round( result_table[0][1]/result_table[2][1],4))\n",
    "print(\"Overall # of misclassified data is \",misclassified)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Including a dummy variable, student, may not lead to a reduction in the test error rate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
